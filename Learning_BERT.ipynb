{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning_BERT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlA9zTxRiO06",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "We will using transfer learning, a Machine Learning technique where a pretrained AI model is used to develop a model for a next or a new project or task. \n",
        "\n",
        "In another words all the work has been done we just need to import the model and use it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4viPJKQujTBR",
        "colab_type": "text"
      },
      "source": [
        "# Credits\n",
        "\n",
        "The developer and developer behind this code is <a href = \" https://github.com/graykode\" >Tae Hwan Jung </a>, please check out his works. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW99sHiijw8F",
        "colab_type": "text"
      },
      "source": [
        "# Idea for this code\n",
        "\n",
        "The basic notion behind this project is used to learn and then apply it using our own methods. \n",
        "\n",
        "We are just going to see  how GPT-2 can be useful for our project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1361_3wC8K-",
        "colab_type": "code",
        "outputId": "30ca786e-2c9e-408e-c379-ada60a135d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Let's clone this repo directly from github to our colab notebook\n",
        "\n",
        "!git clone https://github.com/graykode/gpt-2-Pytorch && cd gpt-2-Pytorch"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2-Pytorch'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/117)   \u001b[K\rremote: Counting objects:   1% (2/117)   \u001b[K\rremote: Counting objects:   2% (3/117)   \u001b[K\rremote: Counting objects:   3% (4/117)   \u001b[K\rremote: Counting objects:   4% (5/117)   \u001b[K\rremote: Counting objects:   5% (6/117)   \u001b[K\rremote: Counting objects:   6% (8/117)   \u001b[K\rremote: Counting objects:   7% (9/117)   \u001b[K\rremote: Counting objects:   8% (10/117)   \u001b[K\rremote: Counting objects:   9% (11/117)   \u001b[K\rremote: Counting objects:  10% (12/117)   \u001b[K\rremote: Counting objects:  11% (13/117)   \u001b[K\rremote: Counting objects:  12% (15/117)   \u001b[K\rremote: Counting objects:  13% (16/117)   \u001b[K\rremote: Counting objects:  14% (17/117)   \u001b[K\rremote: Counting objects:  15% (18/117)   \u001b[K\rremote: Counting objects:  16% (19/117)   \u001b[K\rremote: Counting objects:  17% (20/117)   \u001b[K\rremote: Counting objects:  18% (22/117)   \u001b[K\rremote: Counting objects:  19% (23/117)   \u001b[K\rremote: Counting objects:  20% (24/117)   \u001b[K\rremote: Counting objects:  21% (25/117)   \u001b[K\rremote: Counting objects:  22% (26/117)   \u001b[K\rremote: Counting objects:  23% (27/117)   \u001b[K\rremote: Counting objects:  24% (29/117)   \u001b[K\rremote: Counting objects:  25% (30/117)   \u001b[K\rremote: Counting objects:  26% (31/117)   \u001b[K\rremote: Counting objects:  27% (32/117)   \u001b[K\rremote: Counting objects:  28% (33/117)   \u001b[K\rremote: Counting objects:  29% (34/117)   \u001b[K\rremote: Counting objects:  30% (36/117)   \u001b[K\rremote: Counting objects:  31% (37/117)   \u001b[K\rremote: Counting objects:  32% (38/117)   \u001b[K\rremote: Counting objects:  33% (39/117)   \u001b[K\rremote: Counting objects:  34% (40/117)   \u001b[K\rremote: Counting objects:  35% (41/117)   \u001b[K\rremote: Counting objects:  36% (43/117)   \u001b[K\rremote: Counting objects:  37% (44/117)   \u001b[K\rremote: Counting objects:  38% (45/117)   \u001b[K\rremote: Counting objects:  39% (46/117)   \u001b[K\rremote: Counting objects:  40% (47/117)   \u001b[K\rremote: Counting objects:  41% (48/117)   \u001b[K\rremote: Counting objects:  42% (50/117)   \u001b[K\rremote: Counting objects:  43% (51/117)   \u001b[K\rremote: Counting objects:  44% (52/117)   \u001b[K\rremote: Counting objects:  45% (53/117)   \u001b[K\rremote: Counting objects:  46% (54/117)   \u001b[K\rremote: Counting objects:  47% (55/117)   \u001b[K\rremote: Counting objects:  48% (57/117)   \u001b[K\rremote: Counting objects:  49% (58/117)   \u001b[K\rremote: Counting objects:  50% (59/117)   \u001b[K\rremote: Counting objects:  51% (60/117)   \u001b[K\rremote: Counting objects:  52% (61/117)   \u001b[K\rremote: Counting objects:  53% (63/117)   \u001b[K\rremote: Counting objects:  54% (64/117)   \u001b[K\rremote: Counting objects:  55% (65/117)   \u001b[K\rremote: Counting objects:  56% (66/117)   \u001b[K\rremote: Counting objects:  57% (67/117)   \u001b[K\rremote: Counting objects:  58% (68/117)   \u001b[K\rremote: Counting objects:  59% (70/117)   \u001b[K\rremote: Counting objects:  60% (71/117)   \u001b[K\rremote: Counting objects:  61% (72/117)   \u001b[K\rremote: Counting objects:  62% (73/117)   \u001b[K\rremote: Counting objects:  63% (74/117)   \u001b[K\rremote: Counting objects:  64% (75/117)   \rremote: Counting objects:  65% (77/117)   \u001b[K\rremote: Counting objects:  66% (78/117)   \u001b[K\rremote: Counting objects:  67% (79/117)   \u001b[K\rremote: Counting objects:  68% (80/117)   \u001b[K\rremote: Counting objects:  69% (81/117)   \u001b[K\rremote: Counting objects:  70% (82/117)   \u001b[K\rremote: Counting objects:  71% (84/117)   \u001b[K\rremote: Counting objects:  72% (85/117)   \u001b[K\rremote: Counting objects:  73% (86/117)   \u001b[K\rremote: Counting objects:  74% (87/117)   \u001b[K\rremote: Counting objects:  75% (88/117)   \u001b[K\rremote: Counting objects:  76% (89/117)   \u001b[K\rremote: Counting objects:  77% (91/117)   \u001b[K\rremote: Counting objects:  78% (92/117)   \u001b[K\rremote: Counting objects:  79% (93/117)   \u001b[K\rremote: Counting objects:  80% (94/117)   \u001b[K\rremote: Counting objects:  81% (95/117)   \u001b[K\rremote: Counting objects:  82% (96/117)   \u001b[K\rremote: Counting objects:  83% (98/117)   \u001b[K\rremote: Counting objects:  84% (99/117)   \u001b[K\rremote: Counting objects:  85% (100/117)   \u001b[K\rremote: Counting objects:  86% (101/117)   \u001b[K\rremote: Counting objects:  87% (102/117)   \u001b[K\rremote: Counting objects:  88% (103/117)   \u001b[K\rremote: Counting objects:  89% (105/117)   \u001b[K\rremote: Counting objects:  90% (106/117)   \u001b[K\rremote: Counting objects:  91% (107/117)   \u001b[K\rremote: Counting objects:  92% (108/117)   \u001b[K\rremote: Counting objects:  93% (109/117)   \u001b[K\rremote: Counting objects:  94% (110/117)   \u001b[K\rremote: Counting objects:  95% (112/117)   \u001b[K\rremote: Counting objects:  96% (113/117)   \u001b[K\rremote: Counting objects:  97% (114/117)   \u001b[K\rremote: Counting objects:  98% (115/117)   \u001b[K\rremote: Counting objects:  99% (116/117)   \u001b[K\rremote: Counting objects: 100% (117/117)   \u001b[K\rremote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/66)   \u001b[K\rremote: Compressing objects:   3% (2/66)   \u001b[K\rremote: Compressing objects:   4% (3/66)   \u001b[K\rremote: Compressing objects:   6% (4/66)   \u001b[K\rremote: Compressing objects:   7% (5/66)   \u001b[K\rremote: Compressing objects:   9% (6/66)   \u001b[K\rremote: Compressing objects:  10% (7/66)   \u001b[K\rremote: Compressing objects:  12% (8/66)   \u001b[K\rremote: Compressing objects:  13% (9/66)   \u001b[K\rremote: Compressing objects:  15% (10/66)   \u001b[K\rremote: Compressing objects:  16% (11/66)   \u001b[K\rremote: Compressing objects:  18% (12/66)   \u001b[K\rremote: Compressing objects:  19% (13/66)   \u001b[K\rremote: Compressing objects:  21% (14/66)   \u001b[K\rremote: Compressing objects:  22% (15/66)   \u001b[K\rremote: Compressing objects:  24% (16/66)   \u001b[K\rremote: Compressing objects:  25% (17/66)   \u001b[K\rremote: Compressing objects:  27% (18/66)   \u001b[K\rremote: Compressing objects:  28% (19/66)   \u001b[K\rremote: Compressing objects:  30% (20/66)   \u001b[K\rremote: Compressing objects:  31% (21/66)   \u001b[K\rremote: Compressing objects:  33% (22/66)   \u001b[K\rremote: Compressing objects:  34% (23/66)   \u001b[K\rremote: Compressing objects:  36% (24/66)   \u001b[K\rremote: Compressing objects:  37% (25/66)   \u001b[K\rremote: Compressing objects:  39% (26/66)   \u001b[K\rremote: Compressing objects:  40% (27/66)   \u001b[K\rremote: Compressing objects:  42% (28/66)   \u001b[K\rremote: Compressing objects:  43% (29/66)   \u001b[K\rremote: Compressing objects:  45% (30/66)   \u001b[K\rremote: Compressing objects:  46% (31/66)   \u001b[K\rremote: Compressing objects:  48% (32/66)   \u001b[K\rremote: Compressing objects:  50% (33/66)   \u001b[K\rremote: Compressing objects:  51% (34/66)   \u001b[K\rremote: Compressing objects:  53% (35/66)   \u001b[K\rremote: Compressing objects:  54% (36/66)   \u001b[K\rremote: Compressing objects:  56% (37/66)   \u001b[K\rremote: Compressing objects:  57% (38/66)   \u001b[K\rremote: Compressing objects:  59% (39/66)   \u001b[K\rremote: Compressing objects:  60% (40/66)   \u001b[K\rremote: Compressing objects:  62% (41/66)   \u001b[K\rremote: Compressing objects:  63% (42/66)   \u001b[K\rremote: Compressing objects:  65% (43/66)   \u001b[K\rremote: Compressing objects:  66% (44/66)   \u001b[K\rremote: Compressing objects:  68% (45/66)   \u001b[K\rremote: Compressing objects:  69% (46/66)   \u001b[K\rremote: Compressing objects:  71% (47/66)   \u001b[K\rremote: Compressing objects:  72% (48/66)   \u001b[K\rremote: Compressing objects:  74% (49/66)   \u001b[K\rremote: Compressing objects:  75% (50/66)   \u001b[K\rremote: Compressing objects:  77% (51/66)   \u001b[K\rremote: Compressing objects:  78% (52/66)   \u001b[K\rremote: Compressing objects:  80% (53/66)   \u001b[K\rremote: Compressing objects:  81% (54/66)   \u001b[K\rremote: Compressing objects:  83% (55/66)   \u001b[K\rremote: Compressing objects:  84% (56/66)   \u001b[K\rremote: Compressing objects:  86% (57/66)   \u001b[K\rremote: Compressing objects:  87% (58/66)   \u001b[K\rremote: Compressing objects:  89% (59/66)   \u001b[K\rremote: Compressing objects:  90% (60/66)   \u001b[K\rremote: Compressing objects:  92% (61/66)   \u001b[K\rremote: Compressing objects:  93% (62/66)   \u001b[K\rremote: Compressing objects:  95% (63/66)   \u001b[K\rremote: Compressing objects:  96% (64/66)   \u001b[K\rremote: Compressing objects:  98% (65/66)   \u001b[K\rremote: Compressing objects: 100% (66/66)   \u001b[K\rremote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "Receiving objects:   0% (1/117)   \rReceiving objects:   1% (2/117)   \rReceiving objects:   2% (3/117)   \rReceiving objects:   3% (4/117)   \rReceiving objects:   4% (5/117)   \rReceiving objects:   5% (6/117)   \rReceiving objects:   6% (8/117)   \rReceiving objects:   7% (9/117)   \rReceiving objects:   8% (10/117)   \rReceiving objects:   9% (11/117)   \rReceiving objects:  10% (12/117)   \rReceiving objects:  11% (13/117)   \rReceiving objects:  12% (15/117)   \rReceiving objects:  13% (16/117)   \rReceiving objects:  14% (17/117)   \rReceiving objects:  15% (18/117)   \rReceiving objects:  16% (19/117)   \rReceiving objects:  17% (20/117)   \rReceiving objects:  18% (22/117)   \rReceiving objects:  19% (23/117)   \rReceiving objects:  20% (24/117)   \rReceiving objects:  21% (25/117)   \rReceiving objects:  22% (26/117)   \rReceiving objects:  23% (27/117)   \rReceiving objects:  24% (29/117)   \rReceiving objects:  25% (30/117)   \rReceiving objects:  26% (31/117)   \rReceiving objects:  27% (32/117)   \rReceiving objects:  28% (33/117)   \rReceiving objects:  29% (34/117)   \rReceiving objects:  30% (36/117)   \rReceiving objects:  31% (37/117)   \rReceiving objects:  32% (38/117)   \rReceiving objects:  33% (39/117)   \rReceiving objects:  34% (40/117)   \rReceiving objects:  35% (41/117)   \rReceiving objects:  36% (43/117)   \rReceiving objects:  37% (44/117)   \rReceiving objects:  38% (45/117)   \rReceiving objects:  39% (46/117)   \rReceiving objects:  40% (47/117)   \rReceiving objects:  41% (48/117)   \rReceiving objects:  42% (50/117)   \rReceiving objects:  43% (51/117)   \rReceiving objects:  44% (52/117)   \rReceiving objects:  45% (53/117)   \rReceiving objects:  46% (54/117)   \rReceiving objects:  47% (55/117)   \rReceiving objects:  48% (57/117)   \rReceiving objects:  49% (58/117)   \rReceiving objects:  50% (59/117)   \rReceiving objects:  51% (60/117)   \rReceiving objects:  52% (61/117)   \rReceiving objects:  53% (63/117)   \rReceiving objects:  54% (64/117)   \rReceiving objects:  55% (65/117)   \rReceiving objects:  56% (66/117)   \rReceiving objects:  57% (67/117)   \rReceiving objects:  58% (68/117)   \rReceiving objects:  59% (70/117)   \rReceiving objects:  60% (71/117)   \rReceiving objects:  61% (72/117)   \rReceiving objects:  62% (73/117)   \rReceiving objects:  63% (74/117)   \rReceiving objects:  64% (75/117)   \rReceiving objects:  65% (77/117)   \rReceiving objects:  66% (78/117)   \rReceiving objects:  67% (79/117)   \rReceiving objects:  68% (80/117)   \rReceiving objects:  69% (81/117)   \rReceiving objects:  70% (82/117)   \rReceiving objects:  71% (84/117)   \rReceiving objects:  72% (85/117)   \rReceiving objects:  73% (86/117)   \rReceiving objects:  74% (87/117)   \rReceiving objects:  75% (88/117)   \rReceiving objects:  76% (89/117)   \rReceiving objects:  77% (91/117)   \rReceiving objects:  78% (92/117)   \rReceiving objects:  79% (93/117)   \rReceiving objects:  80% (94/117)   \rReceiving objects:  81% (95/117)   \rReceiving objects:  82% (96/117)   \rReceiving objects:  83% (98/117)   \rReceiving objects:  84% (99/117)   \rReceiving objects:  85% (100/117)   \rReceiving objects:  86% (101/117)   \rReceiving objects:  87% (102/117)   \rReceiving objects:  88% (103/117)   \rReceiving objects:  89% (105/117)   \rReceiving objects:  90% (106/117)   \rReceiving objects:  91% (107/117)   \rReceiving objects:  92% (108/117)   \rReceiving objects:  93% (109/117)   \rremote: Total 117 (delta 45), reused 115 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects:  94% (110/117)   \rReceiving objects:  95% (112/117)   \rReceiving objects:  96% (113/117)   \rReceiving objects:  97% (114/117)   \rReceiving objects:  98% (115/117)   \rReceiving objects:  99% (116/117)   \rReceiving objects: 100% (117/117)   \rReceiving objects: 100% (117/117), 2.38 MiB | 15.84 MiB/s, done.\n",
            "Resolving deltas:   0% (0/45)   \rResolving deltas:   2% (1/45)   \rResolving deltas:   4% (2/45)   \rResolving deltas:   6% (3/45)   \rResolving deltas:   8% (4/45)   \rResolving deltas:  15% (7/45)   \rResolving deltas:  17% (8/45)   \rResolving deltas:  20% (9/45)   \rResolving deltas:  22% (10/45)   \rResolving deltas:  48% (22/45)   \rResolving deltas:  51% (23/45)   \rResolving deltas:  82% (37/45)   \rResolving deltas:  84% (38/45)   \rResolving deltas:  86% (39/45)   \rResolving deltas:  95% (43/45)   \rResolving deltas: 100% (45/45)   \rResolving deltas: 100% (45/45), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Be5CnUZDpMT",
        "colab_type": "code",
        "outputId": "ef38714c-e16c-47c9-c161-2d32dd842385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#next we will go into the directory that we downloaded, followed by the curl command\n",
        "\n",
        "%cd gpt-2-Pytorch\n",
        "\n",
        "#curl is a command line tool to transfer data to or from a server, using any of the supported protocols \n",
        "\n",
        "'''Since we will using AWS to fetch our model details such as weights and parameter we need to Curl command line tool'''\n",
        "!curl --output gpt2-pytorch_model.bin https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin\n",
        "  \n",
        "#Installing the requirements.txt \n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2-Pytorch/gpt-2-Pytorch\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  522M  100  522M    0     0  43.2M      0  0:00:12  0:00:12 --:--:-- 41.6M\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2017.4.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqRKuu-9mpS3",
        "colab_type": "text"
      },
      "source": [
        "# Let's test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwEHWSoyFnOA",
        "colab_type": "code",
        "outputId": "d2fb150d-a583-4164-e899-bd179cadea70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "#open python.main followed by --text and in quotes write your own lines\n",
        "!python main.py --text 'Far across the horizon I see, a small spot of light shining on me and if we hold on tight together we can see the other side of the mountain forever'\n",
        "\n",
        "\"\"\"The model after evaluation will generate it's own line from the data given to it\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=-1, length=-1, nsamples=1, quiet=False, temperature=0.7, text='Far across the horizon I see, a small spot of light shining on me and if we hold on tight together we can see the other side of the mountain forever', top_k=40, unconditional=False)\n",
            "Far across the horizon I see, a small spot of light shining on me and if we hold on tight together we can see the other side of the mountain forever\n",
            "100% 512/512 [00:07<00:00, 70.32it/s]\n",
            "======================================== SAMPLE 1 ========================================\n",
            ".\"\n",
            "\n",
            "I'm not sure what it is about that light that we find ourselves in, but I imagine it's what makes it work.\n",
            "\n",
            "That's where the movie comes in. This is a movie about how to make a movie about your life. It's about how to make a movie about your life, and it's about how to make a movie about your life, and then it's about how to make a movie about your life, too. It's about how to make a movie that makes people cry, about how to make a movie that makes people laugh, about how to make a movie that makes people love you.\n",
            "\n",
            "So how do we make a movie about your life?\n",
            "\n",
            "Here's the thing. When I think about it, I'm so used to making movies about my life, and it's not about a movie about my life. It's about a movie about you, your life. That's it.\n",
            "\n",
            "I'm very proud of the way I made that movie.\n",
            "\n",
            "I'm very proud of the way I made that movie.<|endoftext|>I'm a sucker for the \"I got it on the line\" narrative. I love the idea that we can put these two people in positions of power that are not only willing to make some kind of good deal for them, but also willing to pay for the privilege of doing so. I think that's a pretty good way to go about it. I'm not sure what the point is of that. I think it's a nice idea, but it's not really something that I think is going to get people to do, right?\n",
            "\n",
            "The one thing I do have an interest in is how to move through these different situations in a more responsible way, and how to find an individual who's willing to make a good deal. My advice would be to go on a few dates with a person who says they love you.\n",
            "\n",
            "If it's a good deal, and you make good on it, then you're going to have a chance to make a few good deals. If you're not willing to make some good deals, then I think it's a good idea to go back and make a few good deals.\n",
            "\n",
            "Now, if you're willing to make some good deals, you might be able to do some great things. But if you're not willing to make some good deals, and you're not going to make some good deals, then you won't be able to make any good deals.\n",
            "\n",
            "And\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The model after evaluation will generate it's own line from the data given to it\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bedJW2KzF7D7",
        "colab_type": "code",
        "outputId": "23bd44e4-05fe-4ed1-ea6f-f0743e7e6e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!python main.py --text 'the universe was lying cold in the deepest parts of matter when suddenly it came into being'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=-1, length=-1, nsamples=1, quiet=False, temperature=0.7, text='the universe was lying cold in the deepest parts of matter when suddenly it came into being', top_k=40, unconditional=False)\n",
            "the universe was lying cold in the deepest parts of matter when suddenly it came into being\n",
            "100% 512/512 [00:07<00:00, 72.15it/s]\n",
            "======================================== SAMPLE 1 ========================================\n",
            " and suddenly it was so cold that you could not even breathe!\n",
            "\n",
            "\"……Why are you so calm and calm?\"\n",
            "\n",
            "\"I'm not even sure what you're saying because I'm completely in shock.\"\n",
            "\n",
            "\"What are you saying?\"\n",
            "\n",
            "\"The universe was lying cold in the deepest parts of matter when suddenly it came into being and suddenly it was so cold that you could not even breathe.\"\n",
            "\n",
            "\"……What are you saying?\"\n",
            "\n",
            "\"I know it's impossible but you must know that it's because you're a person who knows things that are impossible and it's because you're a person who's been in the past but now you're completely in shock. You're not even sure what you're doing because you're a person who's been in the past, you're just a person who's been in the past right now.\"\n",
            "\n",
            "\"……Oh, that's right. It's because you're a person who's been in the past……\"\n",
            "\n",
            "\"……I understand. I don't know what you're saying.\"\n",
            "\n",
            "\"……What kind of person is it?\"\n",
            "\n",
            "\"……I don't know who it is. It's because I am an idiot. I'm the only one who knows that it's because I'm a person who's been in the past. I've been there for thousands of years, I'm the only one who knows that it's because I'm a person who was in the past but now you're completely in shock.\"\n",
            "\n",
            "\"……What is it?\"\n",
            "\n",
            "\"……I know what it is. I'm a person who's been in the past but now you're completely in shock. I'm not even sure what you're doing because you're a person who's been in the past, you're just a person who's been in the past right now.\"\n",
            "\n",
            "\"……What kind of person is it?\"\n",
            "\n",
            "\"……I can't help but be very confused. If you're looking for a person who's been in the past but now you're completely in shock, then you should ask me about that person, I'm your only friend. If you ask me about that person, I'm your only friend. If you ask me about that person, I'm your only friend!\"\n",
            "\n",
            "\"……How can you be so confused?\"\n",
            "\n",
            "\"……Well, I can't help but be very confused. If you're looking for someone who's been in the past but now you're completely in shock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_gdZEIDGTwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}